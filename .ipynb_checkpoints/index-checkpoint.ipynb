{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to your Mod 3 Assessment. You will be tested for your understanding of concepts and ability to solve problems that have been covered in class and in the curriculum.\n",
    "\n",
    "Use any libraries you want to solve the problems in the assessment.\n",
    "\n",
    "_Read the instructions carefully_. You will be asked both to write code and respond to a few short answer questions.\n",
    "\n",
    "**Note on the short answer questions**: For the short answer questions please use your own words. The expectation is that you have not copied and pasted from an external source, even if you consult another source to help craft your response. While the short answer questions are not necessarily being assessed on grammatical correctness or sentence structure, you should do your best to communicate yourself clearly.\n",
    "\n",
    "The sections of the assessment are:\n",
    "- Statistical Distributions\n",
    "- Statistical Tests\n",
    "- Bayesian Statistics\n",
    "- Linear Regression and Extensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "# import the necessary libraries\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Statistical Distributions [Suggested time: 25 minutes]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Normal Distributions\n",
    "\n",
    "Say we have check totals for all checks ever written at a TexMex restaurant. \n",
    "\n",
    "The distribution for this population of check totals happens to be normally distributed with a population mean of $\\mu = 20$ and population standard deviation of $\\sigma = 2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.a.1) Write a function to compute the z-scores for single checks of amount `check_amt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(check_amt):\n",
    "    \"\"\"\n",
    "    check_amt = the amount for which we want to compute the z-score\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "def z_score(check_amt):\n",
    "    \n",
    "    \"\"\" Using the formula (X - mu)/std \"\"\"\n",
    "    \n",
    "    return (check_amt - 20)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.a.2) I go to the TexMex restaurant and get a check for 24 dollars. \n",
    "\n",
    "Use your function to compute your check's z-score, and interpret the result using the empirical rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My check has a z-score of 2.0.\n"
     ]
    }
   ],
   "source": [
    "# __SOLUTION__\n",
    "print(\"My check has a z-score of {}.\".format(z_score(24)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "# The z-score of your check tells you how many standard deviations your check amount is away from the mean\n",
    "# check amount. In this case, your check is two standard deviations away from the mean.\n",
    "\n",
    "# According to the empirical rule, 95% of expected check amounts will be within two standard deviations from the mean.\n",
    "# Your check amount is just within this region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.a.3) Using $\\alpha = 0.05$, is my 25 dollar check significantly **greater** than the mean? How do you know this?  \n",
    "\n",
    "Hint: Here's a link to a [z-table](https://www.math.arizona.edu/~rsims/ma464/standardnormaltable.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My check has a z-score of 2.0.\n",
      "The critical threshold z is 1.64.\n"
     ]
    }
   ],
   "source": [
    "# __SOLUTION__\n",
    "print(\"My check has a z-score of {}.\".format(z_score(24)))\n",
    "print(\"The critical threshold z is {}.\".format(round(stats.norm.ppf(0.95),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "# For alpha = 0.05, the critical threshold z for an upper-tailed z-test is 1.64 (this can be found using the linked z-table or scipy.stats.)\n",
    "# We obtain a z-score of 2.5, which is greater than the critical threshold of 1.64. \n",
    "# Thus, my 25 dollar check is significantly greater than the mean at alpha = 0.05. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Confidence Intervals and the Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.b.1) Determine the 95% confidence interval around the mean check total for this population. Interpret your result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% confidence interval is  (16.08, 23.92)\n"
     ]
    }
   ],
   "source": [
    "# __SOLUTION__ \n",
    "# 95% confidence interval has z-score of 1.96 (read where p = 0.975)\n",
    "mean = 20\n",
    "std = 2\n",
    "conf = (mean - 1.96*std, mean + 1.96*std)\n",
    "print(\"The 95% confidence interval is \", conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your written answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA 95% confidence interval means that there is a 95% chance for the interval to contain the true population mean.\\n\\nA confidence interval is an interval containing the true population mean with a certain probability. \\ni.e. For a 95% confidence interval, there is a 95% chance the interval contains the true population mean.\\n\\nFrequentist interpretation of the confidence interval:  \\nWere this procedure to be repeated on 100 samples, approximately 95 of the calculated confidence intervals \\n(which would be different for each sample) would be expected to contain the true population mean.\\n\\nINCORRECT: a confidence interval contains 95% of all values.\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __SOLUTION__\n",
    "\"\"\"\n",
    "A 95% confidence interval means that there is a 95% chance for the interval to contain the true population mean.\n",
    "\n",
    "A confidence interval is an interval containing the true population mean with a certain probability. \n",
    "i.e. For a 95% confidence interval, there is a 95% chance the interval contains the true population mean.\n",
    "\n",
    "Frequentist interpretation of the confidence interval:  \n",
    "Were this procedure to be repeated on 100 samples, approximately 95 of the calculated confidence intervals \n",
    "(which would be different for each sample) would be expected to contain the true population mean.\n",
    "\n",
    "INCORRECT: a confidence interval contains 95% of all values.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.b.2) Imagine that we didn't know how the population of check totals was distributed. How would **sampling** and the **Central Limit Theorem** allow us to **make inferences on the population mean**, i.e. estimate $\\mu, \\sigma$ of the population mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your written answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSolution: The Central Limit Theorem says that we can take repeated samples of the population, \\nand estimate population parameters by finding the average mean and standard deviation of the samples. \\nSample means will also tend to a normal distribution.\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __SOLUTION__\n",
    "\"\"\"\n",
    "Solution: The Central Limit Theorem says that we can take repeated samples of the population, \n",
    "and estimate population parameters by finding the average mean and standard deviation of the samples. \n",
    "Sample means will also tend to a normal distribution.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Statistical Testing [Suggested time: 15 minutes]\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TexMex restaurant recently introduced Queso to its menu.\n",
    "\n",
    "We have random samples of 1000 \"No Queso\" order check totals and 1000 \"Queso\" order check totals for orders made by different customers.\n",
    "\n",
    "In the cell below, we load the sample data for you into the arrays `no_queso` and `queso` for the \"no queso\" and \"queso\" order check totals. Then, we create histograms of the distribution of the check amounts for the \"no queso\" and \"queso\" samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the sample data \n",
    "no_queso = pickle.load(open(\"data/no_queso.pkl\", \"rb\"))\n",
    "queso = pickle.load(open(\"data/queso.pkl\", \"rb\"))\n",
    "\n",
    "# Plot histograms\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.set_title('Sample of Non-Queso Check Totals')\n",
    "ax1.set_xlabel('Amount')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.hist(no_queso, bins=20)\n",
    "\n",
    "ax2.set_title('Sample of Queso Check Totals')\n",
    "ax2.set_xlabel('Amount')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.hist(queso, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "# Load the sample data \n",
    "no_queso = pickle.load(open(\"data/no_queso.pkl\", \"rb\"))\n",
    "queso = pickle.load(open(\"data/queso.pkl\", \"rb\"))\n",
    "\n",
    "# Plot histograms\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.set_title('Sample of Non-Queso Check Totals')\n",
    "ax1.set_xlabel('Amount')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.hist(no_queso, bins=20)\n",
    "\n",
    "ax2.set_title('Sample of Queso Check Totals')\n",
    "ax2.set_xlabel('Amount')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.hist(queso, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Hypotheses and Errors\n",
    "\n",
    "The restaurant owners want to know if customers who order Queso spend **more or less** than customers who do not order Queso.\n",
    "\n",
    "2.a.1) Set up the null $H_{0}$ and alternative hypotheses $H_{A}$ for this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your written answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "\n",
    "\"\"\"\n",
    "Null hypothesis: Customers who order queso spend the same as those who do not order queso. \n",
    "\n",
    "Alternative hypothesis: Customers who order queso do not spend the same as those who do not order queso. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.a.2) What does it mean to make `Type I` and `Type II` errors in this specific context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "\"\"\"\n",
    "Type I: (Rejecting the null hypothesis given it's true): Saying queso customers' total check amounts are different \n",
    "than non-queso customers' total check amounts when they are the same.\n",
    "\n",
    "Type II: (Failing to reject the null hypothesis given it's false): Saying queso customers' total check amounts are \n",
    "the same as non-queso customers' total check amounts when they are different.\n",
    "\"\"\"\n",
    "\n",
    "# Give partial credit to students who describe what type I and type II errors are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Sample Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.b.1) Run a statistical test on the two samples. Use a significance level of $\\alpha = 0.05$. You can assume the two samples have equal variance. Can you reject the null hypothesis? \n",
    "\n",
    "_Hint: Use `scipy.stats`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "\n",
    "# Run a two-tailed t-test\n",
    "print(stats.ttest_ind(no_queso, queso))\n",
    "\n",
    "# Students may compute the critical t-statistics for the rejection region\n",
    "critical_t = (stats.t.ppf(0.025, df=999), stats.t.ppf(0.975, df=999))\n",
    "print(critical_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "# We have enough evidence to reject the null hypothesis at a significance level of alpha = 0.05. We obtain a p-value\n",
    "# much smaller than 0.025 (two-tailed test). Alternatively, our t-statistic is smaller than the critical t-statistic.\n",
    "# Both answers (p-value or critical t-statistic) are valid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Bayesian Statistics [Suggested time: 15 minutes]\n",
    "---\n",
    "### a. Bayes' Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thomas wants to get a new puppy üêï üê∂ üê© \n",
    "\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/rD8R00QOKwfxC/giphy.gif\" />\n",
    "\n",
    "He can choose to get his new puppy either from the pet store or the pound. The probability of him going to the pet store is $0.2$. \n",
    "\n",
    "He can choose to get either a big, medium or small puppy.\n",
    "\n",
    "If he goes to the pet store, the probability of him getting a small puppy is $0.6$. The probability of him getting a medium puppy is $0.3$, and the probability of him getting a large puppy is $0.1$.\n",
    "\n",
    "If he goes to the pound, the probability of him getting a small puppy is $0.1$. The probability of him getting a medium puppy is $0.35$, and the probability of him getting a large puppy is $0.55$.\n",
    "\n",
    "3.a.1) What is the probability of Thomas getting a small puppy? \n",
    "\n",
    "3.a.2) Given that he got a large puppy, what is the probability that Thomas went to the pet store?\n",
    "\n",
    "3.a.3) Given that Thomas got a small puppy, is it more likely that he went to the pet store or to the pound?\n",
    "\n",
    "3.a.4) For Part 2, what is the prior, posterior and likelihood?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans1 = None\n",
    "ans2 = None\n",
    "ans3 = \"answer here\"\n",
    "ans4_prior = \"answer here\"\n",
    "ans4_posterior = \"answer here\"\n",
    "ans4_likelihood = \"answer here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__ \n",
    "ans1 = 0.2\n",
    "ans2 = 0.02/0.46\n",
    "ans3 = \"Pet Store\" # pet store! (0.12 vs 0.08)\n",
    "ans4_prior = \"P(Store)\"\n",
    "ans4_posterior = \"P(Store | Large)\"\n",
    "ans4_likelihood = \"P(Large | Store)\"\n",
    "\n",
    "\"\"\"\n",
    "Question 1:\n",
    "\n",
    "P(Small) = P(Small|Pet Store) + P(Small|Pound) = 0.2*0.6 + 0.8*0.1 = 0.2\n",
    "\n",
    "Question 2:\n",
    "\n",
    "P(Pet Store|Large)  = P(Large|Pet Store)*P(Pet Store) / P(Large) \n",
    "                    = 0.1*0.2 / (0.1*0.2 + 0.55*0.8)\n",
    "                    = 0.02 / 0.46 = 0.04348\n",
    "                    \n",
    "Question 3:\n",
    "\n",
    "P(Pet Store|Small) = 0.6\n",
    "P(Pound|Small) = 0.4\n",
    "\n",
    "More likely he went to the pet store.\n",
    "\n",
    "Question 4:\n",
    "P(Pet Store|Large) = P(Large|Pet Store)*P(Pet Store) / P(Large) \n",
    "\n",
    "Prior: P(Store)\n",
    "Posterior: P(Store | Large)\n",
    "Likelihood: P(Large | Store)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Linear Regression and extensions [Suggested Time: 25 min]\n",
    "---\n",
    "\n",
    "In this section, you'll be using the Advertising data, and you'll be creating linear models that are more complicated than a simple linear regression. The relevant modules have already been imported at the beginning of this notebook. We'll load and prepare the dataset for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       radio   newspaper       sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/advertising.csv').drop('Unnamed: 0',axis=1)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               TV       radio   newspaper       sales\n",
       "count  200.000000  200.000000  200.000000  200.000000\n",
       "mean   147.042500   23.264000   30.554000   14.022500\n",
       "std     85.854236   14.846809   21.778621    5.217457\n",
       "min      0.700000    0.000000    0.300000    1.600000\n",
       "25%     74.375000    9.975000   12.750000   10.375000\n",
       "50%    149.750000   22.900000   25.750000   12.900000\n",
       "75%    218.825000   36.525000   45.100000   17.400000\n",
       "max    296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __SOLUTION__\n",
    "data = pd.read_csv('data/advertising.csv').drop('Unnamed: 0',axis=1)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('sales', axis=1)\n",
    "y = data['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "X = data.drop('sales', axis=1)\n",
    "y = data['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing set. Do not change the random state please!\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y,random_state=2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "# split the data into training and testing set. Do not change the random state please!\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y,random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Multiple Linear Regression\n",
    "\n",
    "In the linear regression section of the curriculum, you've analyzed how TV, Radio and Newspaper spendings individually affected the Sales figures. Here, we'll use all three together in a multiple linear regression model!\n",
    "\n",
    "4.a.1) Create a Correlation Matrix for `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TV</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.054809</td>\n",
       "      <td>0.056648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>radio</th>\n",
       "      <td>0.054809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.354104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newspaper</th>\n",
       "      <td>0.056648</td>\n",
       "      <td>0.354104</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TV     radio  newspaper\n",
       "TV         1.000000  0.054809   0.056648\n",
       "radio      0.054809  1.000000   0.354104\n",
       "newspaper  0.056648  0.354104   1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __SOLUTION__\n",
    "X.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.a.2) Based on this correlation matrix only, would you recommend to use `TV`, `radio` and `newspaper` in the same multiple linear regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your written answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "# The highest correlation can be observed between radio and newspaper. \n",
    "# Since the correlation is only 0.35 (much smaller than what would be considered a high correlation ~>0.7), there\n",
    "# are no multicollinearity issues for the three variables, and from a multicollinearity perspective, \n",
    "# they can be used together in the same model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.a.3) Use StatsModels' `ols`-function to create a multiple linear regression model with `TV`, `radio` and `newspaper` as independent variables and sales as the dependent variable. Use the **training set only** to create the model.\n",
    "\n",
    "Required output: the model summary of this multiple regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>y_train</td>     <th>  R-squared:         </th> <td>   0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   437.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 02 Jan 2020</td> <th>  Prob (F-statistic):</th> <td>9.93e-73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:41:18</td>     <th>  Log-Likelihood:    </th> <td> -286.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   150</td>      <th>  AIC:               </th> <td>   580.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   146</td>      <th>  BIC:               </th> <td>   592.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>         <td>    2.9906</td> <td>    0.347</td> <td>    8.619</td> <td> 0.000</td> <td>    2.305</td> <td>    3.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train.TV</th>        <td>    0.0472</td> <td>    0.002</td> <td>   29.641</td> <td> 0.000</td> <td>    0.044</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train.radio</th>     <td>    0.1726</td> <td>    0.010</td> <td>   17.397</td> <td> 0.000</td> <td>    0.153</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X_train.newspaper</th> <td>    0.0031</td> <td>    0.007</td> <td>    0.471</td> <td> 0.639</td> <td>   -0.010</td> <td>    0.016</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>53.809</td> <th>  Durbin-Watson:     </th> <td>   2.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 145.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.447</td> <th>  Prob(JB):          </th> <td>2.43e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.862</td> <th>  Cond. No.          </th> <td>    432.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                y_train   R-squared:                       0.900\n",
       "Model:                            OLS   Adj. R-squared:                  0.898\n",
       "Method:                 Least Squares   F-statistic:                     437.5\n",
       "Date:                Thu, 02 Jan 2020   Prob (F-statistic):           9.93e-73\n",
       "Time:                        17:41:18   Log-Likelihood:                -286.41\n",
       "No. Observations:                 150   AIC:                             580.8\n",
       "Df Residuals:                     146   BIC:                             592.9\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "Intercept             2.9906      0.347      8.619      0.000       2.305       3.676\n",
       "X_train.TV            0.0472      0.002     29.641      0.000       0.044       0.050\n",
       "X_train.radio         0.1726      0.010     17.397      0.000       0.153       0.192\n",
       "X_train.newspaper     0.0031      0.007      0.471      0.639      -0.010       0.016\n",
       "==============================================================================\n",
       "Omnibus:                       53.809   Durbin-Watson:                   2.091\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              145.586\n",
       "Skew:                          -1.447   Prob(JB):                     2.43e-32\n",
       "Kurtosis:                       6.862   Cond. No.                         432.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __SOLUTION__\n",
    "train_data = pd.concat([X_train,y_train], axis = 1) # needed in the OLS-formula\n",
    "formula = 'y_train ~ X_train.TV + X_train.radio + X_train.newspaper'\n",
    "model = ols(formula = formula, data = train_data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.a.4) Do we have any statistically significant coefficients? If the answer is yes, list them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your written answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "# Since the p-value is very small for TV and radio, they are statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Polynomial terms\n",
    "\n",
    "We'd like to add a bit of complexity to the model created in the example above, and we will do it by adding some polynomial terms. Write a function to calculate train and test error for different polynomial degrees. You'll use `scikit-learn`'s `PolynomialFeatures`.\n",
    "\n",
    "4.b.1) Create the function described above. This function should:\n",
    "* take `degree` as a parameter that will be used to create polynomial features to be used in a linear regression model\n",
    "* create a PolynomialFeatures object for each degree and fit a linear regression model using the transformed data\n",
    "* calculate the mean square error for each level of polynomial\n",
    "* return the `train_error` and `test_error` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression(degree):\n",
    "    \"\"\"\n",
    "    Calculate train and test errorfor a linear regression with polynomial features.\n",
    "    (Hint: use PolynomialFeatures)\n",
    "    \n",
    "    input: Polynomial degree\n",
    "    output: Mean squared error for train and test set\n",
    "    \"\"\"\n",
    "    # // your code here //\n",
    "    \n",
    "    train_error = None\n",
    "    test_error = None\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "def polynomial_regression(degree):\n",
    "    \"\"\"\n",
    "    Calculate train and test errorfor a linear regression with polynomial features.\n",
    "    (Hint: use PolynomialFeatures)\n",
    "    \n",
    "    input: Polynomial degree\n",
    "    output: Mean squared error for train and test set\n",
    "    \"\"\"\n",
    "    poly = PolynomialFeatures(degree=degree,interaction_only=False)\n",
    "    X_poly_train = poly.fit_transform(X_train)\n",
    "    X_poly_test = poly.transform(X_test)\n",
    "    lr_poly = LinearRegression()\n",
    "    lr_poly.fit(X_poly_train,y_train)\n",
    "    train_error = mean_squared_error(y_train, lr_poly.predict(X_poly_train))\n",
    "    test_error = mean_squared_error(y_test, lr_poly.predict(X_poly_test))\n",
    "    return train_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.b.2) Try out your new function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24235967358392063, 0.15281375976869446)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polynomial_regression(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24235967358392063, 0.15281375976869446)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# __SOLUTION__\n",
    "polynomial_regression(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your answers\n",
    "\n",
    "MSE for degree 3:\n",
    "- Train: 0.2423596735839209\n",
    "- Test: 0.15281375973923944\n",
    "\n",
    "MSE for degree 4:\n",
    "- Train: 0.18179109317368244\n",
    "- Test: 1.9522597174462015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.b.3) What is the optimal number of degrees for our polynomial features in this model? In general, how does increasing the polynomial degree relate to the Bias/Variance tradeoff?  (Note that this graph shows RMSE and not MSE.)\n",
    "\n",
    "<img src =\"visuals/rsme_poly_2.png\" width = \"600\">\n",
    "\n",
    "<!---\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "degree = list(range(1, 10 + 1))\n",
    "ax.plot(degree, error_train[0:len(degree)], \"-\", label=\"Train Error\")\n",
    "ax.plot(degree, error_test[0:len(degree)], \"-\", label=\"Test Error\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Polynomial Feature Degree\")\n",
    "ax.set_ylabel(\"Root Mean Squared Error\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Relationship Between Degree and Error\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"visuals/rsme_poly.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\")\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "# The optimal number of features in this example is 3 because the testing error \n",
    "# is minimized at this point, and it increases dramatically with a higher degree polynomial. \n",
    "# As we increase the polynomial features, it is going to cause our training error to decrease, \n",
    "# which decreases the bias but increases the variance (the testing error increases). \n",
    "# In other words, the more complex the model, the higher the chance of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. In general what methods would you can use to reduce overfitting and underfitting? Provide an example for both and explain how each technique works to reduce the problems of underfitting and overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __SOLUTION__\n",
    "# Overfitting: Regularization. With regularization, more complex models are penalized. \n",
    "# This ensures that the models are not trained to too much \"noise.\"\n",
    "\n",
    "# Underfitting: Feature engineering. By adding additional features, you enable your \n",
    "# machine learning models to gain insights about your data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
